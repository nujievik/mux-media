from pathlib import Path
import re

from wcwidth import wcswidth

PROJECT_DIR = Path(__file__).resolve().parent.parent
GEN_BY = "// Auto-generated by " + str(Path(__file__).relative_to(PROJECT_DIR))

SOURCE = PROJECT_DIR / "resources" / "iso639_language_list.cpp"
OUT_ENUM = PROJECT_DIR / "src" / "types" / "lang_code.rs"
OUT_MAP_FROM_STR = PROJECT_DIR / "src" / "types" / "lang_code" / "map_from_str.rs"
OUT_LIST_LANGS = PROJECT_DIR / "src" / "types" / "lang_code" / "list_langs.rs"

def read_language_data(source_path):
    with open(source_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    full_names = []
    codes = []
    max_name_len = 0

    for line in lines:
        if "Reserved for local use" in line:
            continue

        match = re.search(r'{\s*"([^"]*)",\s*"([^"]*)",\s*"([^"]*)",\s*"([^"]*)"', line)
        if match:
            name = match.group(1).strip()
            _codes = [match.group(i).strip() for i in range(2, 5) if match.group(i).strip()]
            if not _codes:
                continue

            full_names.append(name)
            codes.append(_codes)
            max_name_len = max(max_name_len, len(name))

    return full_names, codes, max_name_len


def to_pascal(code: str) -> str:
    return ''.join(word.capitalize() for word in code.split('_'))


def generate_enum(codes, output_path):
    variants = "\n".join(f"    {to_pascal(_codes[0])}," for _codes in codes)

    enum = f"""{GEN_BY}

mod impls;
mod list_langs;
mod map_from_str;
mod set_multiple_priority;

use strum_macros::AsRefStr;

/// Three-letter ISO 639-3 language codes.
#[derive(Copy, Clone, Debug, Eq, Hash, PartialEq, AsRefStr)]
#[strum(serialize_all = "kebab-case")]
pub enum LangCode {{
{variants}
}}
"""

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(enum)
    print("✅ Rust enum generated ->", output_path)


def generate_map_from_str(codes, output_path):
    map_entries = []
    for _codes in codes:
        enum = to_pascal(_codes[0])
        for code in _codes:
            map_entries.append(f'    "{code}" => LangCode::{enum},')

    map_entries = "\n".join(map_entries)

    rust_map = f"""{GEN_BY}

use super::LangCode;
use phf::{{Map, phf_map}};

pub(super) static MAP_FROM_STR: Map<&'static str, LangCode> = phf_map! {{
{map_entries}
}};
"""

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(rust_map)
    print("✅ PHF map generated ->", output_path)


def generate_list_langs(names, codes, max_name_len, output_path):
    NAME_COLUMN = max_name_len + 1
    CODE_COLUMN = 16

    header = "English language name".ljust(NAME_COLUMN)
    for title in ["ISO 639-3 code", "ISO 639-2 code", "ISO 639-1 code"]:
        header += "|" + " " + title.ljust(CODE_COLUMN - 1)

    separator = "-" * NAME_COLUMN + "+" + "+".join(["-" * CODE_COLUMN] * 3)

    def visual_width(s): return wcswidth(s)

    body = []

    for name, code_list in zip(names, codes):
        padding = NAME_COLUMN - visual_width(name)
        line = name + " " * padding

        for code in code_list:
            line += "|" + " " + code.ljust(15)

        while len(code_list) < 3:
            line += "|" + " " + " " * 15
            code_list.append("")

        body.append(line)

    body = "\n".join(body)

    rust_list_langs = f"""{GEN_BY}

pub(super) static LIST_LANGS: &'static str = r#"{header}
{separator}
{body}"#;
"""

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(rust_list_langs)
    print("✅ Help language list generated ->", output_path)


def main():
    names, codes, max_name_len = read_language_data(SOURCE)
    generate_enum(codes, OUT_ENUM)
    generate_map_from_str(codes, OUT_MAP_FROM_STR)
    generate_list_langs(names, codes, max_name_len, OUT_LIST_LANGS)


if __name__ == "__main__":
    main()
